{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task IX. Kolmogorov-Arnold Network (KAN)\n",
    "Implementation of a classical Kolmogorov-Arnold Network with b-splines applied to the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSplineActivation(nn.Module):\n",
    "    def __init__(self, num_bases=10, degree=3, input_dim=784):\n",
    "        super().__init__()\n",
    "        self.num_bases = num_bases\n",
    "        self.degree = degree\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.knots = torch.linspace(0, 1, num_bases + degree + 1)\n",
    "        self.register_buffer(\"knots_buffer\", self.knots)\n",
    "\n",
    "        self.coeffs = nn.Parameter(torch.randn(input_dim, num_bases))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x - x.min()) / (x.max() - x.min() + 1e-6)\n",
    "        B = self.bspline_basis(x)  # (batch, input_dim, num_bases)\n",
    "        B = B.squeeze()\n",
    "        out = torch.einsum('bik,ik->bi', B, self.coeffs)  # (batch, input_dim)\n",
    "        return out\n",
    "\n",
    "    def bspline_basis(self, x):\n",
    "        batch_size, input_dim = x.shape\n",
    "        x = x.unsqueeze(-1)  # (batch, input_dim, 1)\n",
    "        knots = self.knots_buffer\n",
    "        degree = self.degree\n",
    "        num_bases = self.num_bases\n",
    "\n",
    "        B = []\n",
    "        for i in range(num_bases):\n",
    "            left = knots[i]\n",
    "            right = knots[i + 1]\n",
    "            B.append(((x >= left) & (x < right)).float())\n",
    "        B = torch.stack(B, dim=2)  # (batch, input_dim, num_bases)\n",
    "\n",
    "        for d in range(1, degree + 1):\n",
    "            B_new = []\n",
    "            for i in range(num_bases):\n",
    "                denom1 = knots[i + d] - knots[i]\n",
    "                denom2 = knots[i + d + 1] - knots[i + 1]\n",
    "\n",
    "                term1 = 0\n",
    "                if denom1 > 0:\n",
    "                    term1 = ((x.squeeze(-1) - knots[i]) / denom1).unsqueeze(-1) * B[:, :, i]\n",
    "\n",
    "                term2 = 0\n",
    "                if i + 1 < num_bases and denom2 > 0:\n",
    "                    term2 = ((knots[i + d + 1] - x.squeeze(-1)) / denom2).unsqueeze(-1) * B[:, :, i + 1]\n",
    "\n",
    "                B_new.append(term1 + term2)\n",
    "\n",
    "            B = torch.stack(B_new, dim=2)\n",
    "\n",
    "        return B\n",
    "\n",
    "class BSplineKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(784, 784)\n",
    "        self.bkan = BSplineActivation(input_dim=784)\n",
    "        self.linear2 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bkan(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2803\n",
      "Epoch 2, Loss: 0.1053\n",
      "Epoch 3, Loss: 0.0727\n",
      "Epoch 4, Loss: 0.0435\n",
      "Epoch 5, Loss: 0.0325\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BSplineKAN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum KAN\n",
    "\n",
    "A major concern with classical KANs is computational efficiency. The activation functions are not able to be learned in parallel using GPUs, so MLP still dominate deep learning. In the quantum architecture, we can try to compute multiple parameters in parallel, speeding up the training process of KANs and increasing their practicality. Inspired by https://arxiv.org/pdf/2410.04435"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
